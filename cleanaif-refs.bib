@article{Aguilera2022,
  title = {How Particular Is the Physics of the Free Energy Principle?},
  author = {Aguilera, Miguel and Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L.},
  date = {2022-03-01},
  journaltitle = {Physics of Life Reviews},
  shortjournal = {Physics of Life Reviews},
  volume = {40},
  pages = {24--50},
  issn = {1571-0645},
  doi = {10.1016/j.plrev.2021.11.001},
  url = {https://www.sciencedirect.com/science/article/pii/S1571064521000749},
  abstract = {The free energy principle (FEP) states that any dynamical system can be interpreted as performing Bayesian inference upon its surrounding environment. Although, in theory, the FEP applies to a wide variety of systems, there has been almost no direct exploration or demonstration of the principle in concrete systems. In this work, we examine in depth the assumptions required to derive the FEP in the simplest possible set of systems – weakly-coupled non-equilibrium linear stochastic systems. Specifically, we explore (i) how general the requirements imposed on the statistical structure of a system are and (ii) how informative the FEP is about the behaviour of such systems. We discover that two requirements of the FEP – the Markov blanket condition (i.e. a statistical boundary precluding direct coupling between internal and external states) and stringent restrictions on its solenoidal flows (i.e. tendencies driving a system out of equilibrium) – are only valid for a very narrow space of parameters. Suitable systems require an absence of perception-action asymmetries that is highly unusual for living systems interacting with an environment. More importantly, we observe that a mathematically central step in the argument, connecting the behaviour of a system to variational inference, relies on an implicit equivalence between the dynamics of the average states of a system with the average of the dynamics of those states. This equivalence does not hold in general even for linear stochastic systems, since it requires an effective decoupling from the system's history of interactions. These observations are critical for evaluating the generality and applicability of the FEP and indicate the existence of significant problems of the theory in its current form. These issues make the FEP, as it stands, not straightforwardly applicable to the simple linear systems studied here and suggest that more development is needed before the theory could be applied to the kind of complex systems that describe living and cognitive processes.},
  keywords = {Bayesian inference,Free energy principle,Linear non-equilibrium systems,Markov blanket,Unread},
  file = {/home/filconscious/Library/How particular is the physics of the free energy principle - Aguilera et al.pdf}
}

@article{Badcock2019,
  title = {The Hierarchically Mechanistic Mind: An Evolutionary Systems Theory of the Human Brain, Cognition, and Behavior},
  author = {Badcock, Paul B. and Friston, Karl J. and Ramstead, Maxwell J.D. and Ploeger, Annemie and Hohwy, Jakob},
  date = {2019},
  journaltitle = {Cognitive, Affective and Behavioral Neuroscience},
  volume = {19},
  number = {6},
  eprint = {31115833},
  eprinttype = {pmid},
  pages = {1319--1351},
  publisher = {{Cognitive, Affective, \& Behavioral Neuroscience}},
  issn = {15307026},
  doi = {10.3758/s13415-019-00721-3},
  abstract = {The purpose of this review was to integrate leading paradigms in psychology and neuroscience with a theory of the embodied, situated human brain, called the Hierarchically Mechanistic Mind (HMM). The HMM describes the brain as a complex adaptive system that functions to minimize the entropy of our sensory and physical states via action-perception cycles generated by hierarchical neural dynamics. First, we review the extant literature on the hierarchical structure of the brain. Next, we derive the HMM from a broader evolutionary systems theory that explains neural structure and function in terms of dynamic interactions across four nested levels of biological causation (i.e., adaptation, phylogeny, ontogeny, and mechanism). We then describe how the HMM aligns with a global brain theory in neuroscience called the free-energy principle, leveraging this theory to mathematically formulate neural dynamics across hierarchical spatiotemporal scales. We conclude by exploring the implications of the HMM for psychological inquiry.},
  langid = {english},
  keywords = {active inference,adaptive prior,developmental psychology,evolutionary psychology,evolutionary systems theory,free energy principle,hierarchically mechanistic mind,Unread},
  file = {/home/filconscious/Library/The hierarchically mechanistic mind an evolutionary systems theory - Badcock.pdf}
}

@inproceedings{Baltieri2017,
  title = {An Active Inference Implementation of Phototaxis},
  booktitle = {Proceedings of {{ECAL}} 2017 - The14th {{European Conference}} on {{Artificial Life}}},
  author = {Baltieri, Manuel and Buckley, Christopher L.},
  date = {2017},
  pages = {36--43},
  location = {{Lyon, France}},
  doi = {10.7551/ecal_a_011},
  url = {https://doi.org/10.1162/isal_a_011},
  abstract = {Active inference is emerging as a possible unifying theory of perception and action in cognitive and computational neuroscience. On this theory, perception is a process of inferring the causes of sensory data by minimising the error between actual sensations and those predicted by an inner \$\textbackslash backslash\$emph\{generative\} (probabilistic) model. Action on the other hand is drawn as a process that modifies the world such that the consequent sensory input meets expectations encoded in the same internal model. These two processes, inferring properties of the world and inferring actions needed to meet expectations, close the sensory/motor loop and suggest a deep symmetry between action and perception. In this work we present a simple agent-based model inspired by this new theory that offers insights on some of its central ideas. Previous implementations of active inference have typically examined a "perception-oriented" view of this theory, assuming that agents are endowed with a detailed generative model of their surrounding environment. In contrast, we present an "action-oriented" solution showing how adaptive behaviour can emerge even when agents operate with a simple model which bears little resemblance to their environment. We examine how various parameters of this formulation allow phototaxis and present an example of a different, "pathological" behaviour.},
  eventtitle = {{{ECAL}} 2017},
  isbn = {978-0-262-34633-7},
  langid = {english},
  keywords = {action,active inference,phototaxis,Read},
  file = {/home/filconscious/Library/An active inference implementation of phototaxis - Baltieri Buckley.pdf}
}

@article{Biehl2018,
  title = {Expanding the Active Inference Landscape: More Intrinsic Motivations in the Perception-Action Loop},
  author = {Biehl, Martin and Guckelsberger, Christian and Salge, Christoph and Smith, Simón C. and Polani, Daniel},
  date = {2018},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {12},
  pages = {1--26},
  issn = {16625218},
  doi = {10.3389/fnbot.2018.00045},
  abstract = {Active inference is an ambitious theory that treats perception, inference, and action selection of autonomous agents under the heading of a single principle. It suggests biologically plausible explanations for many cognitive phenomena, including consciousness. In active inference, action selection is driven by an objective function that evaluates possible future actions with respect to current, inferred beliefs about the world. Active inference at its core is independent from extrinsic rewards, resulting in a high level of robustness across e.g., different environments or agent morphologies. In the literature, paradigms that share this independence have been summarized under the notion of intrinsic motivations. In general and in contrast to active inference, these models of motivation come without a commitment to particular inference and action selection mechanisms. In this article, we study if the inference and action selection machinery of active inference can also be used by alternatives to the originally included intrinsic motivation. The perception-action loop explicitly relates inference and action selection to the environment and agent memory, and is consequently used as foundation for our analysis. We reconstruct the active inference approach, locate the original formulation within, and show how alternative intrinsic motivations can be used while keeping many of the original features intact. Furthermore, we illustrate the connection to universal reinforcement learning by means of our formalism. Active inference research may profit from comparisons of the dynamics induced by alternative intrinsic motivations. Research on intrinsic motivations may profit from an additional way to implement intrinsically motivated agents that also share the biological plausibility of active inference.},
  issue = {AUG},
  keywords = {active inference,empowerment,free energy principle,intrinsic motivation,perception-action loop,Seminal,universal reinforcement learning,Unread,variational Bayesian inference},
  file = {/home/filconscious/Library/Expanding the Active Inference Landscape - Biehl et al.pdf}
}

@article{Biehl2021,
  title = {A Technical Critique of Some Parts of the Free Energy Principle},
  author = {Biehl, Martin and Pollock, Felix A. and Kanai, Ryota},
  date = {2021},
  journaltitle = {Entropy},
  volume = {23},
  number = {3},
  issn = {1099-4300},
  doi = {10.3390/e23030293},
  abstract = {We summarize the original formulation of the free energy principle and highlight some technical issues. We discuss how these issues affect related results involving generalised coordinates and, where appropriate, mention consequences for and reveal, up to now unacknowledged, differences from newer formulations of the free energy principle. In particular, we reveal that various definitions of the “Markov blanket” proposed in different works are not equivalent. We show that crucial steps in the free energy argument, which involve rewriting the equations of motion of systems with Markov blankets, are not generally correct without additional (previously unstated) assumptions. We prove by counterexamples that the original free energy lemma, when taken at face value, is wrong. We show further that this free energy lemma, when it does hold, implies the equality of variational density and ergodic conditional density. The interpretation in terms of Bayesian inference hinges on this point, and we hence conclude that it is not sufficiently justified. Additionally, we highlight that the variational densities presented in newer formulations of the free energy principle and lemma are parametrised by different variables than in older works, leading to a substantially different interpretation of the theory. Note that we only highlight some specific problems in the discussed publications. These problems do not rule out conclusively that the general ideas behind the free energy principle are worth pursuing.},
  keywords = {free energy principle,Markov blanket,stochastic differential equations,Unread},
  file = {/home/filconscious/Library/A Technical Critique of Some Parts of the Free Energy Principle - Biehl et al.pdf}
}

@article{Bogacz2017,
  title = {A Tutorial on the Free-Energy Framework for Modelling Perception and Learning},
  author = {Bogacz, Rafal},
  date = {2017},
  journaltitle = {Journal of Mathematical Psychology},
  volume = {76},
  eprint = {28298703},
  eprinttype = {pmid},
  pages = {198--211},
  publisher = {{Elsevier Inc.}},
  issn = {10960880},
  doi = {10.1016/j.jmp.2015.11.003},
  url = {https://doi.org/10.1016/j.jmp.2015.11.003},
  abstract = {This paper provides an easy to follow tutorial on the free-energy framework for modelling perception developed by Friston, which extends the predictive coding model of Rao and Ballard. These models assume that the sensory cortex infers the most likely values of attributes or features of sensory stimuli from the noisy inputs encoding the stimuli. Remarkably, these models describe how this inference could be implemented in a network of very simple computational elements, suggesting that this inference could be performed by biological networks of neurons. Furthermore, learning about the parameters describing the features and their uncertainty is implemented in these models by simple rules of synaptic plasticity based on Hebbian learning. This tutorial introduces the free-energy framework using very simple examples, and provides step-by-step derivations of the model. It also discusses in more detail how the model could be implemented in biological neural circuits. In particular, it presents an extended version of the model in which the neurons only sum their inputs, and synaptic plasticity only depends on activity of pre-synaptic and post-synaptic neurons.},
  issue = {Pt B},
  langid = {english},
  keywords = {Annotated,free energy principle},
  file = {/home/filconscious/Library/A tutorial on the free-energy framework for modelling perception - Bogacz.pdf}
}

@article{Buckley2017,
  title = {The Free Energy Principle for Action and Perception: A Mathematical Review},
  author = {Buckley, Christopher L. and Kim, Chang Sub and McGregor, Simon and Seth, Anil K.},
  date = {2017},
  journaltitle = {Journal of Mathematical Psychology},
  volume = {81},
  pages = {55--79},
  publisher = {{Elsevier Inc.}},
  issn = {10960880},
  doi = {10.1016/j.jmp.2017.09.004},
  url = {http://dx.doi.org/10.1016/j.jmp.2017.09.004},
  abstract = {The ‘free energy principle' (FEP) has been suggested to provide a unified theory of the brain, integrating data and theory relating to action, perception, and learning. The theory and implementation of the FEP combines insights from Helmholtzian ‘perception as inference', machine learning theory, and statistical thermodynamics. Here, we provide a detailed mathematical evaluation of a suggested biologically plausible implementation of the FEP that has been widely used to develop the theory. Our objectives are (i) to describe within a single article the mathematical structure of this implementation of the FEP; (ii) provide a simple but complete agent-based model utilising the FEP and (iii) to disclose the assumption structure of this implementation of the FEP to help elucidate its significance for the brain sciences.},
  langid = {english},
  keywords = {action,agent-based model,Bayesian brain,free energy principle,inference,perception,Read},
  file = {/home/filconscious/Library/The free energy principle for action and perception A mathematical - Buckley et al.pdf}
}

@article{Clark2013b,
  title = {Whatever next? {{Predictive}} Brains, Situated Agents, and the Future of Cognitive Science},
  author = {Clark, Andy},
  date = {2013},
  journaltitle = {Behavioral and Brain Sciences},
  volume = {36},
  number = {3},
  eprint = {23663408},
  eprinttype = {pmid},
  pages = {181--204},
  issn = {14691825},
  doi = {10.1017/S0140525X12000477},
  abstract = {Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this hierarchical prediction machine approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency. © 2013 Cambridge University Press.},
  langid = {english},
  keywords = {action,attention,Bayesian brain,expectation,generative model,generative models,hierarchy,perception,precision,prediction,prediction error,predictive coding,Read,top-down processing},
  file = {/home/filconscious/Library/Whatever Next Predictive brains - Clark A.pdf}
}

@article{Colombo2021,
  title = {Non-Equilibrium Thermodynamics and the Free Energy Principle in Biology},
  author = {Colombo, Matteo and Palacios, Patricia},
  date = {2021-08-23},
  journaltitle = {Biology \& Philosophy},
  shortjournal = {Biology \& Philosophy},
  volume = {36},
  number = {5},
  pages = {41},
  issn = {1572-8404},
  doi = {10.1007/s10539-021-09818-x},
  url = {https://doi.org/10.1007/s10539-021-09818-x},
  abstract = {According to the free energy principle, life is an “inevitable and emergent property of any (ergodic) random dynamical system at non-equilibrium steady state that possesses a Markov blanket” (Friston in J R Soc Interface 10(86):20130475, 2013). Formulating a principle for the life sciences in terms of concepts from statistical physics, such as random dynamical system, non-equilibrium steady state and ergodicity, places substantial constraints on the theoretical and empirical study of biological systems. Thus far, however, the physics foundations of the free energy principle have received hardly any attention. Here, we start to fill this gap and analyse some of the challenges raised by applications of statistical physics for modelling biological targets. Based on our analysis, we conclude that model-building grounded in the free energy principle exacerbates a trade-off between generality and realism, because of a fundamental mismatch between its physics assumptions and the properties of actual biological targets.},
  keywords = {Unread},
  file = {/home/filconscious/Library/Non-equilibrium thermodynamics and the free energy principle in biology - Colombo Palacios.pdf}
}

@article{DaCosta2020,
  title = {Active Inference on Discrete State-Spaces: A Synthesis},
  author = {Da Costa, Lancelot and Parr, Thomas and Sajid, Noor and Veselic, Sebastijan and Neacsu, Victorita and Friston, Karl},
  date = {2020-12-01},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {99},
  pages = {102447},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2020.102447},
  url = {https://www.sciencedirect.com/science/article/pii/S0022249620300857},
  abstract = {Active inference is a normative principle underwriting perception, action, planning, decision-making and learning in biological or artificial agents. From its inception, its associated process theory has grown to incorporate complex generative models, enabling simulation of a wide range of complex behaviours. Due to successive developments in active inference, it is often difficult to see how its underlying principle relates to process theories and practical implementation. In this paper, we try to bridge this gap by providing a complete mathematical synthesis of active inference on discrete state-space models. This technical summary provides an overview of the theory, derives neuronal dynamics from first principles and relates this dynamics to biological processes. Furthermore, this paper provides a fundamental building block needed to understand active inference for mixed generative models; allowing continuous sensations to inform discrete representations. This paper may be used as follows: to guide research towards outstanding challenges, a practical guide on how to implement active inference to simulate experimental behaviour, or a pointer towards various in-silico neurophysiological responses that may be used to make empirical predictions.},
  langid = {english},
  keywords = {active inference,free energy principle,Markov decision process,process theory,Read,Seminal,variational Bayesian inference},
  file = {/home/filconscious/Library/Active inference on discrete state-spaces A synthesis v3 - Da Costa et al.pdf}
}

@article{DaCosta2022,
  title = {How {{Active Inference Could Help Revolutionise Robotics}}},
  author = {Da Costa, Lancelot and Lanillos, Pablo and Sajid, Noor and Friston, Karl and Khan, Shujhat},
  date = {2022},
  journaltitle = {Entropy},
  volume = {24},
  number = {3},
  issn = {1099-4300},
  doi = {10.3390/e24030361},
  abstract = {Recent advances in neuroscience have characterised brain function using mathematical formalisms and first principles that may be usefully applied elsewhere. In this paper, we explain how active inference\&mdash;a well-known description of sentient behaviour from neuroscience\&mdash;can be exploited in robotics. In short, active inference leverages the processes thought to underwrite human behaviour to build effective autonomous systems. These systems show state-of-the-art performance in several robotics settings; we highlight these and explain how this framework may be used to advance robotics.},
  langid = {english},
  keywords = {adaptive robots,Bayesian inference,filtering,free energy,generative model,model-based control,neurotechnology,Unread},
  file = {/home/filconscious/Library/How Active Inference Could Help Revolutionise Robotics - Da Costa et al.pdf}
}

@inproceedings{DeMaele2021,
  title = {Disentangling {{What}} and {{Where}} for {{3D Object-Centric Representations Through Active Inference}}},
  booktitle = {Machine {{Learning}} and {{Principles}} and {{Practice}} of {{Knowledge Discovery}} in {{Databases}}},
  author = {family=Maele, given=Toon Van, prefix=de, useprefix=true and Verbelen, Tim and Çatal, Ozan and Dhoedt, Bart},
  editor = {Kamp, Michael and Koprinska, Irena and Bibal, Adrien and Bouadi, Tassadit and Frénay, Benoît and Galárraga, Luis and Oramas, José and Adilova, Linara and Krishnamurthy, Yamuna and Kang, Bo and Largeron, Christine and Lijffijt, Jefrey and Viard, Tiphaine and Welke, Pascal and Ruocco, Massimiliano and Aune, Erlend and Gallicchio, Claudio and Schiele, Gregor and Pernkopf, Franz and Blott, Michaela and Fröning, Holger and Schindler, Günther and Guidotti, Riccardo and Monreale, Anna and Rinzivillo, Salvatore and Biecek, Przemyslaw and Ntoutsi, Eirini and Pechenizkiy, Mykola and Rosenhahn, Bodo and Buckley, Christopher and Cialfi, Daniela and Lanillos, Pablo and Ramstead, Maxwell and Verbelen, Tim and Ferreira, Pedro M. and Andresini, Giuseppina and Malerba, Donato and Medeiros, Ibéria and Fournier-Viger, Philippe and Nawaz, M. Saqib and Ventura, Sebastian and Sun, Meng and Zhou, Min and Bitetta, Valerio and Bordino, Ilaria and Ferretti, Andrea and Gullo, Francesco and Ponti, Giovanni and Severini, Lorenzo and Ribeiro, Rita and Gama, João and Gavaldà, Ricard and Cooper, Lee and Ghazaleh, Naghmeh and Richiardi, Jonas and Roqueiro, Damian and Saldana Miranda, Diego and Sechidis, Konstantinos and Graça, Guilherme},
  date = {2021},
  pages = {701--714},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  abstract = {Although modern object detection and classification models achieve high accuracy, these are typically constrained in advance on a fixed train set and are therefore not flexible to deal with novel, unseen object categories. Moreover, these models most often operate on a single frame, which may yield incorrect classifications in case of ambiguous viewpoints. In this paper, we propose an active inference agent that actively gathersevidence for object classifications, and can learn novel object categories over time. Drawing inspiration from the human brain, we build object-centric generative models composed of two information streams, a what- and a where-stream. The what-stream predicts whether the observed object belongs to a specific category, while the where-stream is responsible for representing the object in its internal 3D reference frame. We show that our agent (i) is able to learn representations for many object categories in an unsupervised way, (ii) achieves state-of-the-art classification accuracies, actively resolving ambiguity when required and (iii) identifies novel object categories. Furthermore, we validate our system in an end-to-end fashion where the agent is able to search for an object at a given pose from a pixel-based rendering. We believe that this is a first step towards building modular, intelligent systems that can be used for a wide range of tasks involving three dimensional objects.},
  isbn = {978-3-030-93736-2},
  langid = {english},
  keywords = {Unread},
  file = {/home/filconscious/Library/Disentangling What and Where for 3D Object-Centric Representations Through Active Inference - de Maele et al.pdf}
}

@inproceedings{Fountas2020,
  title = {Deep Active Inference Agents Using {{Monte-Carlo}} Methods},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Fountas, Zafeirios and Sajid, Noor and Mediano, Pedro and Friston, Karl},
  editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M.F. and Lin, H.},
  date = {2020},
  volume = {33},
  pages = {11662--11675},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2020/file/865dfbde8a344b44095495f3591f7407-Paper.pdf},
  eventtitle = {{{NeurIPS}} 33},
  langid = {english},
  keywords = {Read},
  file = {/home/filconscious/Library/Deep active inference agents using Monte-Carlo methods - Fountas et al.pdf}
}

@article{Friston2005,
  title = {A Theory of Cortical Responses},
  author = {Friston, Karl},
  date = {2005},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {360},
  number = {1456},
  pages = {815--836},
  issn = {0962-8436},
  doi = {10.1098/rstb.2005.1622},
  url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.2005.1622 http://www.royalsocietypublishing.org/doi/10.1098/rstb.2005.1622},
  langid = {english},
  keywords = {Annotated,free energy principle,generative models,hierarchical inference,perceptual inference,Seminal},
  file = {/home/filconscious/Library/A Theory of Cortical Responses - Friston.pdf}
}

@article{Friston2006,
  title = {A Free Energy Principle for the Brain},
  author = {Friston, Karl and Kilner, James and Harrison, Lee},
  date = {2006},
  journaltitle = {Journal of Physiology Paris},
  volume = {100},
  number = {1--3},
  eprint = {17097864},
  eprinttype = {pmid},
  pages = {70--87},
  issn = {09284257},
  doi = {10.1016/j.jphysparis.2006.10.001},
  abstract = {By formulating Helmholtz's ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses. In this paper, we show these perceptual processes are just one aspect of emergent behaviours of systems that conform to a free energy principle. The free energy considered here measures the difference between the probability distribution of environmental quantities that act on the system and an arbitrary distribution encoded by its configuration. The system can minimise free energy by changing its configuration to affect the way it samples the environment or change the distribution it encodes. These changes correspond to action and perception respectively and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment assumes that the system's state and structure encode an implicit and probabilistic model of the environment. We will look at the models entailed by the brain and how minimisation of its free energy can explain its dynamics and structure. © 2006.},
  langid = {english},
  keywords = {action,Annotated,attention,free energy principle,hierarchical inference,perception,Relevant,variational Bayesian inference},
  file = {/home/filconscious/Library/A free energy principle for the brain - Friston et al.pdf}
}

@article{Friston2007,
  title = {Free-Energy and the Brain},
  author = {Friston, Karl J. and Stephan, Klaas E.},
  date = {2007},
  journaltitle = {Synthese},
  volume = {159},
  number = {3},
  pages = {417--458},
  issn = {00397857},
  doi = {10.1007/s11229-007-9237-y},
  url = {https://doi.org/10.1007/s11229-007-9237-y},
  abstract = {If one formulates Helmholtz's ideas about perception in terms of modern-day theories one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts. Using constructs from statistical physics it can be shown that the problems of inferring what cause our sensory inputs and learning causal regularities in the sensorium can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory information is generated. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of the brain's organisation and responses. In this paper, we suggest that these perceptual processes are just one emergent property of systems that conform to a free-energy principle. The free-energy considered here represents a bound on the surprise inherent in any exchange with the environment, under expectations encoded by its state or configuration. A system can minimise free-energy by changing its configuration to change the way it samples the environment, or to change its expectations. These changes correspond to action and perception, respectively, and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment implies that the system's state and structure encode an implicit and probabilistic model of the environment. We will look at models entailed by the brain and how minimisation of free-energy can explain its dynamics and structure. © 2007 Springer Science+Business Media B.V.},
  langid = {english},
  keywords = {action,Annotated,attention,free energy,free energy principle,hierarchical inference,learning,perception,variational Bayesian inference},
  file = {/home/filconscious/Library/Free-energy and the brain - Friston.pdf}
}

@article{Friston2009,
  title = {The Free-Energy Principle: A Rough Guide to the Brain?},
  author = {Friston, Karl},
  date = {2009},
  journaltitle = {Trends in Cognitive Sciences},
  volume = {13},
  number = {7},
  eprint = {19559644},
  eprinttype = {pmid},
  pages = {293--301},
  issn = {13646613},
  doi = {10.1016/j.tics.2009.04.005},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S136466130900117X},
  abstract = {This article reviews a free-energy formulation that advances Helmholtz's agenda to find principles of brain function based on conservation laws and neuronal energy. It rests on advances in statistical physics, theoretical biology and machine learning to explain a remarkable range of facts about brain structure and function. We could have just scratched the surface of what this formulation offers; for example, it is becoming clear that the Bayesian brain is just one facet of the free-energy principle and that perception is an inevitable consequence of active exchange with the environment. Furthermore, one can see easily how constructs like memory, attention, value, reinforcement and salience might disclose their simple relationships within this framework. © 2009 Elsevier Ltd. All rights reserved.},
  langid = {english},
  keywords = {Annotated,Read},
  file = {/home/filconscious/Library/The Free Energy Principle A Rough Guide to the Brain - K Friston.pdf}
}

@article{Friston2010b,
  title = {Action and Behavior: A Free-Energy Formulation},
  author = {Friston, Karl J. and Daunizeau, Jean and Kilner, James and Kiebel, Stefan J.},
  date = {2010},
  journaltitle = {Biological Cybernetics},
  volume = {102},
  number = {3},
  eprint = {20148260},
  eprinttype = {pmid},
  pages = {227--260},
  issn = {03401200},
  doi = {10.1007/s00422-010-0364-z},
  url = {https://doi.org/10.1007/s00422-010-0364-z},
  abstract = {We have previously tried to explain perceptual inference and learning under a free-energy principle that pursues Helmholtz's agenda to understand the brain in terms of energy minimization. It is fairly easy to show that making inferences about the causes of sensory data can be cast as the minimization of a free-energy bound on the likelihood of sensory inputs, given an internal model of how they were caused. In this article, we consider what would happen if the data themselves were sampled to minimize this bound. It transpires that the ensuing active sampling or inference is mandated by ergodic arguments based on the very existence of adaptive agents. Furthermore, it accounts for many aspects of motor behavior; from retinal stabilization to goal-seeking. In particular, it suggests that motor control can be understood as fulfilling prior expectations about proprioceptive sensations. This formulation can explain why adaptive behavior emerges in biological agents and suggests a simple alternative to optimal control theory. We illustrate these points using simulations of oculomotor control and then apply to same principles to cued and goal-directed movements. In short, the free-energy formulation may provide an alternative perspective on the motor control that places it in an intimate relationship with perception. © 2010 Springer-Verlag.},
  langid = {english},
  keywords = {Annotated,Bayesian brain,Bayesian cognition,control,hierarchical inference,priors,Relevant},
  file = {/home/filconscious/Library/Action and behavior A free-energy formulation - Friston et al.pdf}
}

@article{Friston2012g,
  title = {Active Inference and Agency: Optimal Control without Cost Functions},
  author = {Friston, Karl and Samothrakis, Spyridon and Montague, Read},
  date = {2012},
  journaltitle = {Biological Cybernetics},
  volume = {106},
  number = {8--9},
  eprint = {22864468},
  eprinttype = {pmid},
  pages = {523--541},
  issn = {03401200},
  doi = {10.1007/s00422-012-0512-8},
  url = {https://doi.org/10.1007/s00422-012-0512-8},
  abstract = {This paper describes a variational free-energy formulation of (partially observable) Markov decision problems in decision making under uncertainty. We show that optimal control can be cast as active inference. In active inference, both action and posterior beliefs about hidden states minimise a free energy bound on the negative log-likelihood of observed states, under a generative model. In this setting, reward or cost functions are absorbed into prior beliefs about state transitions and terminal states. Effectively, this converts optimal control into a pure inference problem, enabling the application of standard Bayesian filtering techniques.We then consider optimal trajectories that rest on posterior beliefs about hidden states in the future. Crucially, this entails modelling control as a hidden state that endows the generative model with a representation of agency. This leads to a distinction between models with and without inference on hidden control states; namely, agency-free and agency-based models, respectively. © Springer-Verlag 2012.},
  langid = {english},
  keywords = {action,agency,Bayesian brain,Bayesian cognition,free energy principle,inference,Markov decision processes,optimal control,POMDP,Read},
  file = {/home/filconscious/Library/Active inference and agency optimal control without cost functions - Friston.pdf}
}

@article{Friston2015,
  title = {Active Inference and Epistemic Value},
  author = {Friston, Karl and Rigoli, Francesco and Ognibene, Dimitri and Mathys, Christoph and Fitzgerald, Thomas and Pezzulo, Giovanni},
  date = {2015},
  journaltitle = {Cognitive Neuroscience},
  volume = {6},
  number = {4},
  eprint = {25689102},
  eprinttype = {pmid},
  pages = {187--214},
  publisher = {{Routledge}},
  issn = {17588936},
  doi = {10.1080/17588928.2015.1020053},
  url = {http://dx.doi.org/10.1080/17588928.2015.1020053},
  abstract = {We offer a formal treatment of choice behavior based on the premise that agents minimize the expected free energy of future outcomes. Crucially, the negative free energy or quality of a policy can be decomposed into extrinsic and epistemic (or intrinsic) value. Minimizing expected free energy is therefore equivalent to maximizing extrinsic value or expected utility (defined in terms of prior preferences or goals), while maximizing information gain or intrinsic value (or reducing uncertainty about the causes of valuable outcomes). The resulting scheme resolves the exploration-exploitation dilemma: Epistemic value is maximized until there is no further information gain, after which exploitation is assured through maximization of extrinsic value. This is formally consistent with the Infomax principle, generalizing formulations of active vision based upon salience (Bayesian surprise) and optimal decisions based on expected utility and risk-sensitive (Kullback-Leibler) control. Furthermore, as with previous active inference formulations of discrete (Markovian) problems, ad hoc softmax parameters become the expected (Bayes-optimal) precision of beliefs about, or confidence in, policies. This article focuses on the basic theory, illustrating the ideas with simulations. A key aspect of these simulations is the similarity between precision updates and dopaminergic discharges observed in conditioning paradigms.},
  langid = {english},
  keywords = {active inference,agency,Bayesian inference,Bayesian surprise,bounded rationality,epistemic value,exploitation,exploration,free energy principle,information gain,Read,utility theory},
  file = {/home/filconscious/Library/Active inference and epistemic value - Friston et al.pdf}
}

@article{Friston2016,
  title = {Active Inference and Learning},
  author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O'Doherty, John and Pezzulo, Giovanni},
  date = {2016},
  journaltitle = {Neuroscience and Biobehavioral Reviews},
  volume = {68},
  eprint = {27375276},
  eprinttype = {pmid},
  pages = {862--879},
  publisher = {{Elsevier Ltd}},
  issn = {18737528},
  doi = {10.1016/j.neubiorev.2016.06.022},
  url = {http://dx.doi.org/10.1016/j.neubiorev.2016.06.022},
  abstract = {This paper offers an active inference account of choice behaviour and learning. It focuses on the distinction between goal-directed and habitual behaviour and how they contextualise each other. We show that habits emerge naturally (and autodidactically) from sequential policy optimisation when agents are equipped with state-action policies. In active inference, behaviour has explorative (epistemic) and exploitative (pragmatic) aspects that are sensitive to ambiguity and risk respectively, where epistemic (ambiguity-resolving) behaviour enables pragmatic (reward-seeking) behaviour and the subsequent emergence of habits. Although goal-directed and habitual policies are usually associated with model-based and model-free schemes, we find the more important distinction is between belief-free and belief-based schemes. The underlying (variational) belief updating provides a comprehensive (if metaphorical) process theory for several phenomena, including the transfer of dopamine responses, reversal learning, habit formation and devaluation. Finally, we show that active inference reduces to a classical (Bellman) scheme, in the absence of ambiguity.},
  langid = {english},
  keywords = {active inference,Bayesian inference,Bayesian surprise,epistemic value,exploitation,exploration,free energy principle,habit learning,information gain,Read},
  file = {/home/filconscious/Library/Active inference and learning - Friston et al.pdf}
}

@article{Friston2017,
  title = {Active Inference: A Process Theory},
  author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and Pezzulo, Giovanni},
  date = {2017},
  journaltitle = {Neural Computation},
  volume = {29},
  number = {1},
  pages = {1--49},
  doi = {10.1162/NECO_a_00912},
  url = {https://doi.org/10.1162/NECO_a_00912},
  langid = {english},
  keywords = {Annotated},
  file = {/home/filconscious/Library/Active Inference A Process Theory.pdf}
}

@article{Friston2017a,
  title = {Active Inference, Curiosity and Insight},
  author = {Friston, Karl J. and Lin, Marco and Frith, Christopher D. and Pezzulo, Giovanni and Hobson, J. Allan},
  date = {2017},
  journaltitle = {Neural Computation},
  volume = {29},
  number = {10},
  pages = {2633--2683},
  doi = {10.1162/NECO_a_00999},
  url = {https://doi.org/10.1162/neco_a_00999},
  langid = {english},
  keywords = {active inference,curiosity,free energy,free energy minimisation,Markov decision process,Relevant,Unread},
  file = {/home/filconscious/Library/Active Inference, Curiosity and Insight - Friston et al.pdf}
}

@article{Friston2019,
  title = {A Free Energy Principle for a Particular Physics},
  author = {Friston, Karl},
  date = {2019},
  pages = {1--140},
  url = {http://arxiv.org/abs/1906.10184},
  abstract = {This monograph attempts a theory of every 'thing' that can be distinguished from other things in a statistical sense. The ensuing statistical independencies, mediated by Markov blankets, speak to a recursive composition of ensembles (of things) at increasingly higher spatiotemporal scales. This decomposition provides a description of small things; e.g., quantum mechanics - via the Schrodinger equation, ensembles of small things - via statistical mechanics and related fluctuation theorems, through to big things - via classical mechanics. These descriptions are complemented with a Bayesian mechanics for autonomous or active things. Although this work provides a formulation of every thing, its main contribution is to examine the implications of Markov blankets for self-organisation to nonequilibrium steady-state. In brief, we recover an information geometry and accompanying free energy principle that allows one to interpret the internal states of something as representing or making inferences about its external states. The ensuing Bayesian mechanics is compatible with quantum, statistical and classical mechanics and may offer a formal description of lifelike particles.},
  langid = {english},
  keywords = {active inference,active particles,autopoiesis,Bayesian brain,entropy,free energy,free energy principle,Markov blankets,nonequilibrium steady-state,random dynamical attractor,self-organisation,Unread,variational Bayesian inference},
  file = {/home/filconscious/Library/A free energy principle for a particula physics - Friston.pdf}
}

@article{Friston2021,
  title = {Sophisticated Inference},
  author = {Friston, Karl and Da Costa, Lancelot and Hafner, Danijar and Hesp, Casper and Parr, Thomas},
  date = {2021-02-24},
  journaltitle = {Neural Computation},
  volume = {33},
  number = {3},
  pages = {713--763},
  publisher = {{MIT Press}},
  issn = {0899-7667},
  doi = {10.1162/neco_a_01351},
  url = {https://doi.org/10.1162/neco_a_01351},
  urldate = {2021-03-03},
  abstract = {Active inference offers a first principle account of sentient behavior, from which special and important cases?for example, reinforcement learning, active learning, Bayes optimal inference, Bayes optimal design?can be derived. Active inference finesses the exploitation-exploration dilemma in relation to prior preferences by placing information gain on the same footing as reward or value. In brief, active inference replaces value functions with functionals of (Bayesian) beliefs, in the form of an expected (variational) free energy. In this letter, we consider a sophisticated kind of active inference using a recursive form of expected free energy. Sophistication describes the degree to which an agent has beliefs about beliefs. We consider agents with beliefs about the counterfactual consequences of action for states of affairs and beliefs about those latent states. In other words, we move from simply considering beliefs about ?what would happen if I did that? to ?what I would believe about what would happen if I did that.? The recursive form of the free energy functional effectively implements a deep tree search over actions and outcomes in the future. Crucially, this search is over sequences of belief states as opposed to states per se. We illustrate the competence of this scheme using numerical simulations of deep decision problems.},
  keywords = {Unread},
  file = {/home/filconscious/Library/Sophisticated Inference - Friston et al.pdf}
}

@article{Friston2021a,
  title = {World Model Learning and Inference},
  author = {Friston, Karl and Moran, Rosalyn J. and Nagai, Yukie and Taniguchi, Tadahiro and Gomi, Hiroaki and Tenenbaum, Josh},
  date = {2021-12-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {144},
  pages = {573--590},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2021.09.011},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608021003610},
  abstract = {Understanding information processing in the brain—and creating general-purpose artificial intelligence—are long-standing aspirations of scientists and engineers worldwide. The distinctive features of human intelligence are high-level cognition and control in various interactions with the world including the self, which are not defined in advance and are vary over time. The challenge of building human-like intelligent machines, as well as progress in brain science and behavioural analyses, robotics, and their associated theoretical formalisations, speaks to the importance of the world-model learning and inference. In this article, after briefly surveying the history and challenges of internal model learning and probabilistic learning, we introduce the free energy principle, which provides a useful framework within which to consider neuronal computation and probabilistic world models. Next, we showcase examples of human behaviour and cognition explained under that principle. We then describe symbol emergence in the context of probabilistic modelling, as a topic at the frontiers of cognitive robotics. Lastly, we review recent progress in creating human-like intelligence by using novel probabilistic programming languages. The striking consensus that emerges from these studies is that probabilistic descriptions of learning and inference are powerful and effective ways to create human-like artificial intelligent machines and to understand intelligence in the context of how humans interact with their world.},
  keywords = {Bayesian inference,Cognitive development,Free energy principle,Generative model,Predictive coding,Probabilistic inference,Unread},
  file = {/home/filconscious/Library/World model learning and inference - Friston et al.pdf}
}

@unpublished{Friston2022b,
  title = {Designing Ecosystems of Intelligence from First Principles},
  author = {Friston, Karl J and Ramstead, Maxwell J D and Kiefer, Alex B and Tschantz, Alexander and Buckley, Christopher L and Albarracin, Mahault and Pitliya, Riddhi J and Heins, Conor and Klein, Brennan and Millidge, Beren and Sakthivadivel, Dalton A R and Smithe, Toby St Clere and Koudahl, Magnus and Tremblay, Safae Essafi and Petersen, Capm and Fung, Kaiser and Fox, Jason G and Swanson, Steven and Mapes, Dan and René, Gabriel},
  date = {2022},
  eprint = {2212.01354v1},
  eprinttype = {arxiv},
  eprintclass = {cs.AI},
  pages = {1--39},
  doi = {10.48550/arXiv.2212.01354},
  url = {https://arxiv.org/abs/2212.01354},
  langid = {english},
  keywords = {Adaptation and Self-Organizing Systems (nlin.AO),Artificial Intelligence (cs.AI),FOS: Computer and information sciences,FOS: Physical sciences,Unread},
  file = {/home/filconscious/Library/Designing Ecosystems of Intelligence from First Principles - Friston et al.pdf}
}

@article{Gottwald2020,
  title = {The Two Kinds of Free Energy and the {{Bayesian}} Revolution},
  author = {Gottwald, Sebastian and Braun, Daniel A.},
  date = {2020},
  journaltitle = {PLOS Computational Biology},
  volume = {16},
  number = {12},
  pages = {1--32},
  publisher = {{Public Library of Science}},
  doi = {10.1371/journal.pcbi.1008420},
  url = {https://doi.org/10.1371/journal.pcbi.1008420},
  abstract = {The concept of free energy has its origins in 19th century thermodynamics, but has recently found its way into the behavioral and neural sciences, where it has been promoted for its wide applicability and has even been suggested as a fundamental principle of understanding intelligent behavior and brain function. We argue that there are essentially two different notions of free energy in current models of intelligent agency, that can both be considered as applications of Bayesian inference to the problem of action selection: one that appears when trading off accuracy and uncertainty based on a general maximum entropy principle, and one that formulates action selection in terms of minimizing an error measure that quantifies deviations of beliefs and policies from given reference models. The first approach provides a normative rule for action selection in the face of model uncertainty or when information processing capabilities are limited. The second approach directly aims to formulate the action selection problem as an inference problem in the context of Bayesian brain theories, also known as Active Inference in the literature. We elucidate the main ideas and discuss critical technical and conceptual issues revolving around these two notions of free energy that both claim to apply at all levels of decision-making, from the high-level deliberation of reasoning down to the low-level information processing of perception.},
  langid = {english},
  keywords = {active inference,agency,constraints,free energy,Read,Relevant,utility,variational Bayesian inference},
  file = {/home/filconscious/Library/The two kinds of free energy - S1 Appendix - Gottwald Braun.pdf;/home/filconscious/Library/The two kinds of free energy - S2 Appendix - Gottwald Braun.pdf;/home/filconscious/Library/The two kinds of free energy - S3 Appendix - Gottwald Braun.pdf;/home/filconscious/Library/The two kinds of free energy - S4 Appendix - Gottwald Braun.pdf;/home/filconscious/Library/The two kinds of free energy and the Bayesian Revolution - Gottwald Braun 1.pdf;/home/filconscious/Library/The Two Kinds of Free Energy and the Bayesian Revolution - Gottwald Braun 2.pdf}
}

@article{Kaplan2018a,
  title = {Planning and Navigation as Active Inference},
  author = {Kaplan, Raphael and Friston, Karl J.},
  date = {2018},
  journaltitle = {Biological Cybernetics},
  volume = {112},
  number = {4},
  pages = {323--343},
  publisher = {{Springer Berlin Heidelberg}},
  issn = {14320770},
  doi = {10.1007/s00422-018-0753-2},
  abstract = {This paper introduces an active inference formulation of planning and navigation. It illustrates how the exploitation–exploration dilemma is dissolved by acting to minimise uncertainty (i.e. expected surprise or free energy). We use simulations of a maze problem to illustrate how agents can solve quite complicated problems using context sensitive prior preferences to form subgoals. Our focus is on how epistemic behaviour—driven by novelty and the imperative to reduce uncertainty about the world—contextualises pragmatic or goal-directed behaviour. Using simulations, we illustrate the underlying process theory with synthetic behavioural and electrophysiological responses during exploration of a maze and subsequent navigation to a target location. An interesting phenomenon that emerged from the simulations was a putative distinction between ‘place cells'—that fire when a subgoal is reached—and ‘path cells'—that fire until a subgoal is reached.},
  keywords = {active inference,Bayesian inference,curiosity,epistemic value,exploitation,exploration,free energy,novelty,Relevant,salience,Unread},
  file = {/home/filconscious/Library/Planning And Navigation As Active Inference - Kaplan Friston.pdf}
}

@article{Keller2018,
  title = {Predictive Processing: A Canonical Cortical Computation},
  author = {Keller, Georg B. and Mrsic-Flogel, Thomas D.},
  date = {2018},
  journaltitle = {Neuron},
  volume = {100},
  number = {2},
  eprint = {30359606},
  eprinttype = {pmid},
  pages = {424--435},
  publisher = {{Elsevier Inc.}},
  issn = {10974199},
  doi = {10.1016/j.neuron.2018.10.003},
  url = {https://doi.org/10.1016/j.neuron.2018.10.003},
  abstract = {This perspective describes predictive processing as a computational framework for understanding cortical function in the context of emerging evidence, with a focus on sensory processing. We discuss how the predictive processing framework may be implemented at the level of cortical circuits and how its implementation could be falsified experimentally. Lastly, we summarize the general implications of predictive processing on cortical function in healthy and diseased states. In this perspective, Keller and Mrsic-Flogel describe the advantages of predictive processing as a computational framework for understanding cortical function in the context of emerging evidence with a focus on sensory processing.},
  keywords = {canonical microcircuit,cortex,predictive coding,predictive processing,Relevant,sensory processing,Unread},
  file = {/home/filconscious/Library/Predictive Processing A Canonical Cortical Computation - Keller et al.pdf}
}

@unpublished{Lanillos2021,
  title = {Active Inference in Robotics and Artificial Agents: {{Survey}} and Challenges},
  author = {Lanillos, Pablo and Meo, Cristian and Pezzato, Corrado and Meera, Ajith Anil and Baioumy, Mohamed and Ohata, Wataru and Tschantz, Alexander and Millidge, Beren and Wisse, Martijn and Buckley, Christopher L. and Tani, Jun},
  date = {2021},
  eprint = {2112.01871v1},
  eprinttype = {arxiv},
  eprintclass = {cs.RO},
  pages = {1--20},
  url = {https://arxiv.org/abs/2112.01871},
  langid = {english},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG),Robotics (cs.RO),Unread},
  file = {/home/filconscious/Library/Active Inference in Robotics and Artificial Agents Survey and Challenges - Lanillos et al.pdf}
}

@article{Loeb2014,
  title = {Bayesian Action \& Perception: Representing the World in the Brain},
  author = {Loeb, Gerald E. and Fishel, Jeremy A.},
  date = {2014},
  journaltitle = {Frontiers in Neuroscience},
  volume = {8},
  pages = {1--13},
  issn = {1662453X},
  doi = {10.3389/fnins.2014.00341},
  abstract = {Theories of perception seek to explain how sensory data are processed to identify previously experienced objects, but they usually do not consider the decisions and effort that goes into acquiring the sensory data. Identification of objects according to their tactile properties requires active exploratory movements. The sensory data thereby obtained depend on the details of those movements, which human subjects change rapidly and seemingly capriciously. Bayesian Exploration is an algorithm that uses prior experience to decide which next exploratory movement should provide the most useful data to disambiguate the most likely possibilities. In previous studies, a simple robot equipped with a biomimetic tactile sensor and operated according to Bayesian Exploration performed in a manner similar to and actually better than humans on a texture identification task. Expanding on this, "Bayesian Action and Perception" refers to the construction and querying of an associative memory of previously experienced entities containing both sensory data and the motor programs that elicited them. We hypothesize that this memory can be queried (i) to identify useful next exploratory movements during identification of an unknown entity ("action for perception") or (ii) to characterize whether an unknown entity is fit for purpose ("perception for action") or (iii) to recall what actions might be feasible for a known entity (Gibsonian affordance). The biomimetic design of this mechatronic system may provide insights into the neuronal basis of biological action and perception.},
  issue = {OCT},
  keywords = {affordance,Bayesian brain,Bayesian exploration,perception,somatosensory cortex,tactile sensing,touch,Unread},
  file = {/home/filconscious/Library/Bayesian Action&Perception - Loeb Fishel.pdf}
}

@inproceedings{Mazzaglia2022,
  title = {Curiosity-Driven Exploration via Latent {{Bayesian}} Surprise},
  booktitle = {{{AAAI}} Conference on Artificial Intelligence},
  author = {Mazzaglia, Pietro and Catal, Ozan and Verbelen, Tim and Dhoedt, Bart},
  date = {2022},
  pages = {1--13},
  url = {https://lbsexploration.github.io/},
  langid = {english},
  keywords = {Unread},
  file = {/home/filconscious/Library/Curiosity-Driven Exploration via Latent Bayesian Surprise - Mazzaglia et al.pdf}
}

@article{Mazzaglia2022a,
  title = {The {{Free Energy Principle}} for {{Perception}} and {{Action}}: {{A Deep Learning Perspective}}},
  author = {Mazzaglia, Pietro and Verbelen, Tim and Çatal, Ozan and Dhoedt, Bart},
  date = {2022},
  journaltitle = {Entropy},
  volume = {24},
  number = {2},
  pages = {1--22},
  issn = {1099-4300},
  doi = {10.3390/e24020301},
  url = {https://www.mdpi.com/1099-4300/24/2/301},
  abstract = {The free energy principle, and its corollary active inference, constitute a bio-inspired theory that assumes biological agents act to remain in a restricted set of preferred states of the world, i.e., they minimize their free energy. Under this principle, biological agents learn a generative model of the world and plan actions in the future that will maintain the agent in an homeostatic state that satisfies its preferences. This framework lends itself to being realized in silico, as it comprehends important aspects that make it computationally affordable, such as variational inference and amortized planning. In this work, we investigate the tool of deep learning to design and realize artificial agents based on active inference, presenting a deep-learning oriented presentation of the free energy principle, surveying works that are relevant in both machine learning and active inference areas, and discussing the design choices that are involved in the implementation process. This manuscript probes newer perspectives for the active inference framework, grounding its theoretical aspects into more pragmatic affairs, offering a practical guide to active inference newcomers and a starting point for deep learning practitioners that would like to investigate implementations of the free energy principle.},
  langid = {english},
  keywords = {active inference,deep learning,free energy principle,machine learning,Unread},
  file = {/home/filconscious/Library/The Free Energy Principle for Perception and Action A Deep Learning Perspective - Mazzaglia et al.pdf}
}

@unpublished{Millidge2020d,
  title = {Whence the Expected Free Energy?},
  author = {Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L},
  date = {2020},
  eprint = {2004.08128v5},
  eprinttype = {arxiv},
  eprintclass = {cs.AI},
  pages = {1--25},
  url = {http://arxiv.org/abs/2004.08128},
  abstract = {The Expected Free Energy (EFE) is a central quantity in the theory of active inference. It is the quantity that all active inference agents are mandated to minimize through action, and its decomposition into extrinsic and intrinsic value terms is key to the balance of exploration and exploitation that active inference agents evince. Despite its importance, the mathematical origins of this quantity and its relation to the Variational Free Energy (VFE) remain unclear. In this paper, we investigate the origins of the EFE in detail and show that it is not simply "the free energy in the future". We present a functional that we argue is the natural extension of the VFE, but which actively discourages exploratory behaviour, thus demonstrating that exploration does not directly follow from free energy minimization into the future. We then develop a novel objective, the Free-Energy of the Expected Future (FEEF), which possesses both the epistemic component of the EFE as well as an intuitive mathematical grounding as the divergence between predicted and desired futures.},
  langid = {english},
  keywords = {Read},
  file = {/home/filconscious/Library/Whence the Expected Free Energy - Millidge et al.pdf}
}

@unpublished{Millidge2021,
  title = {A Mathematical Walkthrough and Discussion of the Free Energy Principle},
  author = {Millidge, Beren and Seth, Anil and Buckley, Christopher L},
  date = {2021},
  eprint = {2108.13343v2},
  eprinttype = {arxiv},
  eprintclass = {cs.AI},
  pages = {1--34},
  doi = {10.48550/ARXIV.2108.13343},
  url = {https://arxiv.org/abs/2108.13343},
  langid = {english},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Unread},
  file = {/home/filconscious/Library/A Mathematical Walkthrough and Discussion of the Free Energy Principle - Millidge et al.pdf}
}

@article{Millidge2021b,
  title = {Whence the {{Expected Free Energy}}?},
  author = {Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L.},
  date = {2021-02-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {33},
  number = {2},
  pages = {447--482},
  issn = {0899-7667},
  doi = {10.1162/neco_a_01354},
  url = {https://doi.org/10.1162/neco_a_01354},
  urldate = {2022-11-23},
  abstract = {The expected free energy (EFE) is a central quantity in the theory of active inference. It is the quantity that all active inference agents are mandated to minimize through action, and its decomposition into extrinsic and intrinsic value terms is key to the balance of exploration and exploitation that active inference agents evince. Despite its importance, the mathematical origins of this quantity and its relation to the variational free energy (VFE) remain unclear. In this letter, we investigate the origins of the EFE in detail and show that it is not simply ”the free energy in the future.” We present a functional that we argue is the natural extension of the VFE but actively discourages exploratory behavior, thus demonstrating that exploration does not directly follow from free energy minimization into the future. We then develop a novel objective, the free energy of the expected future (FEEF), which possesses both the epistemic component of the EFE and an intuitive mathematical grounding as the divergence between predicted and desired futures.},
  langid = {english},
  keywords = {Unread},
  file = {/home/filconscious/Library/Whence the expected free energy - Millidge et al.pdf}
}

@article{Parr2017,
  title = {The Active Construction of the Visual World},
  author = {Parr, Thomas and Friston, Karl J.},
  date = {2017},
  journaltitle = {Neuropsychologia},
  volume = {104},
  pages = {92--101},
  publisher = {{Elsevier Ltd}},
  issn = {18733514},
  doi = {10.1016/j.neuropsychologia.2017.08.003},
  url = {http://dx.doi.org/10.1016/j.neuropsychologia.2017.08.003},
  abstract = {What we see is fundamentally dependent on where we look. Despite this seemingly obvious statement, many accounts of the neurobiology underpinning visual perception fail to consider the active nature of how we sample our sensory world. This review offers an overview of the neurobiology of visual perception, which begins with the control of saccadic eye movements. Starting from here, we can follow the anatomy backwards, to try to understand the functional architecture of neuronal networks that support the interrogation of a visual scene. Many of the principles encountered in this exercise are equally applicable to other perceptual modalities. For example, the somatosensory system, like the visual system, requires the sampling of data through mobile receptive epithelia. Analysis of a somatosensory scene depends on what is palpated, in much the same way that visual analysis relies on what is foveated. The discussion here is structured around the anatomical systems involved in active vision and visual scene construction, but will use these systems to introduce some general theoretical considerations. We will additionally highlight points of contact between the biology and the pathophysiology that has been proposed to cause a clinical disorder of scene construction – spatial hemineglect.},
  issue = {August},
  keywords = {attention,Bayesian brain,hemineglect,memory,saccades,salience,scene construction,Unread},
  file = {/home/filconscious/Library/The Active Construction of the Visual World - Parr Friston.pdf}
}

@article{Parr2018d,
  title = {The Discrete and Continuous Brain: From Decisions to Movement---and Back Again},
  author = {Parr, Thomas and Friston, Karl J. and Shankar, Tanmay},
  date = {2018},
  journaltitle = {Neural Computation},
  volume = {30},
  number = {9},
  pages = {2319--2347},
  doi = {10.1162/neco_a_01102},
  url = {https://doi.org/10.1162/neco_a_01102},
  langid = {english},
  keywords = {active inference,free energy,free energy minimisation,free energy principle,Markov Decision Process,Relevant,Unread},
  file = {/home/filconscious/Library/The Discrete and Continuous Brain From Decisions to Movement - Parr Friston.pdf}
}

@article{Parr2019,
  title = {Perceptual Awareness and Active Inference},
  author = {Parr, Thomas and Corcoran, Andrew W and Friston, Karl J and Hohwy, Jakob},
  date = {2019},
  journaltitle = {Neuroscience of Consciousness},
  volume = {2019},
  number = {1},
  pages = {1--15},
  issn = {2057-2107},
  doi = {10.1093/nc/niz012},
  url = {https://doi.org/10.1093/nc/niz012},
  abstract = {Perceptual awareness depends upon the way in which we engage with our sensorium. This notion is central to active inference, a theoretical framework that treats perception and action as inferential processes. This variational perspective on cognition formalizes the notion of perception as hypothesis testing and treats actions as experiments that are designed (in part) to gather evidence for or against alternative hypotheses. The common treatment of perception and action affords a useful interpretation of certain perceptual phenomena whose active component is often not acknowledged. In this article, we start by considering Troxler fading – the dissipation of a peripheral percept during maintenance of fixation, and its recovery during free (saccadic) exploration. This offers an important example of the failure to maintain a percept without actively interrogating a visual scene. We argue that this may be understood in terms of the accumulation of uncertainty about a hypothesized stimulus when free exploration is disrupted by experimental instructions or pathology. Once we take this view, we can generalize the idea of using bodily (oculomotor) action to resolve uncertainty to include the use of mental (attentional) actions for the same purpose. This affords a useful way to think about binocular rivalry paradigms, in which perceptual changes need not be associated with an overt movement.},
  langid = {english},
  keywords = {active inference,awareness,Bayesian brain,Bayesian inference,binocular rivalry,Relevant,troxler fading,Unread},
  file = {/home/filconscious/Library/Perceptual awareness and active inference - Parr et al.pdf}
}

@article{Parr2020a,
  title = {Prefrontal Computation as Active Inference},
  author = {Parr, Thomas and Rikhye, Rajeev Vijay and Halassa, Michael M and Friston, Karl J},
  date = {2020},
  journaltitle = {Cerebral Cortex},
  volume = {30},
  number = {2},
  pages = {682--695},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhz118},
  url = {https://doi.org/10.1093/cercor/bhz118},
  urldate = {2021-03-03},
  abstract = {The prefrontal cortex is vital for a range of cognitive processes, including working memory, attention, and decision-making. Notably, its absence impairs the performance of tasks requiring the maintenance of information through a delay period. In this paper, we formulate a rodent task—which requires maintenance of delay-period activity—as a Markov decision process and treat optimal task performance as an (active) inference problem. We simulate the behavior of a Bayes optimal mouse presented with 1 of 2 cues that instructs the selection of concurrent visual and auditory targets on a trial-by-trial basis. Formulating inference as message passing, we reproduce features of neuronal coupling within and between prefrontal regions engaged by this task. We focus on the micro-circuitry that underwrites delay-period activity and relate it to functional specialization within the prefrontal cortex in primates. Finally, we simulate the electrophysiological correlates of inference and demonstrate the consequences of lesions to each part of our in silico prefrontal cortex. In brief, this formulation suggests that recurrent excitatory connections—which support persistent neuronal activity—encode beliefs about transition probabilities over time. We argue that attentional modulation can be understood as the contextualization of sensory input by these persistent beliefs.},
  langid = {english},
  keywords = {Relevant,Unread},
  file = {/home/filconscious/Library/Prefrontal Computation as Active Inference - Parr et al.pdf}
}

@article{Pezzulo2015,
  title = {Active Inference, Homeostatic Regulation and Adaptive Behavioural Control},
  author = {Pezzulo, Giovanni and Rigoli, Francesco and Friston, Karl},
  date = {2015},
  journaltitle = {Progress in Neurobiology},
  volume = {134},
  eprint = {26365173},
  eprinttype = {pmid},
  pages = {17--35},
  publisher = {{Elsevier Ltd}},
  issn = {18735118},
  doi = {10.1016/j.pneurobio.2015.09.001},
  url = {http://dx.doi.org/10.1016/j.pneurobio.2015.09.001},
  abstract = {We review a theory of homeostatic regulation and adaptive behavioural control within the Active Inference framework. Our aim is to connect two research streams that are usually considered independently; namely, Active Inference and associative learning theories of animal behaviour. The former uses a probabilistic (Bayesian) formulation of perception and action, while the latter calls on multiple (Pavlovian, habitual, goal-directed) processes for homeostatic and behavioural control. We offer a synthesis these classical processes and cast them as successive hierarchical contextualisations of sensorimotor constructs, using the generative models that underpin Active Inference. This dissolves any apparent mechanistic distinction between the optimization processes that mediate classical control or learning. Furthermore, we generalize the scope of Active Inference by emphasizing interoceptive inference and homeostatic regulation. The ensuing homeostatic (or allostatic) perspective provides an intuitive explanation for how priors act as drives or goals to enslave action, and emphasises the embodied nature of inference.},
  langid = {english},
  keywords = {active inference,adaptive control,homeostatic regulation,model-based control,model-free control,Pavlovian control,Read},
  file = {/home/filconscious/Library/Active inference homeostatic regulation and adaptive behavioural control - Pezzulo et al.pdf}
}

@article{Pezzulo2024,
  title = {Active Inference as a Theory of Sentient Behavior},
  author = {Pezzulo, Giovanni and Parr, Thomas and Friston, Karl},
  date = {2024-02-01},
  journaltitle = {Biological Psychology},
  shortjournal = {Biological Psychology},
  volume = {186},
  pages = {108741},
  issn = {0301-0511},
  doi = {10.1016/j.biopsycho.2023.108741},
  url = {https://www.sciencedirect.com/science/article/pii/S0301051123002612},
  urldate = {2024-01-22},
  abstract = {This review paper offers an overview of the history and future of active inference—a unifying perspective on action and perception. Active inference is based upon the idea that sentient behavior depends upon our brains’ implicit use of internal models to predict, infer, and direct action. Our focus is upon the conceptual roots and development of this theory of (basic) sentience and does not follow a rigid chronological narrative. We trace the evolution from Helmholtzian ideas on unconscious inference, through to a contemporary understanding of action and perception. In doing so, we touch upon related perspectives, the neural underpinnings of active inference, and the opportunities for future development. Key steps in this development include the formulation of predictive coding models and related theories of neuronal message passing, the use of sequential models for planning and policy optimization, and the importance of hierarchical (temporally) deep internal (i.e., generative or world) models. Active inference has been used to account for aspects of anatomy and neurophysiology, to offer theories of psychopathology in terms of aberrant precision control, and to unify extant psychological theories. We anticipate further development in all these areas and note the exciting early work applying active inference beyond neuroscience. This suggests a future not just in biology, but in robotics, machine learning, and artificial intelligence.},
  keywords = {Active inference,Generative model,Predictive coding,Unread},
  file = {/home/filconscious/Library/Active inference as a theory of sentient behavior - Pezzulo et al.pdf;/home/filconscious/Zotero/storage/FP5H6QER/S0301051123002612.html}
}

@unpublished{Ramstead2022,
  title = {On {{Bayesian}} Mechanics: {{A}} Physics of and by Beliefs},
  author = {Ramstead, Maxwell J D and Sakthivadivel, Dalton A R and Heins, Conor and Koudahl, Magnus and Millidge, Beren and Da Costa, Lancelot and Klein, Brennan and Friston, Karl J},
  date = {2022},
  eprint = {2205.11543},
  eprinttype = {arxiv},
  eprintclass = {cond-mat.stat-mech},
  pages = {1--51},
  url = {https://arxiv.org/abs/2205.11543},
  langid = {english},
  keywords = {Adaptation and Self-Organizing Systems (nlin.AO),Biological Physics (physics.bio-ph),Dynamical Systems (math.DS),FOS: Mathematics,FOS: Physical sciences,Statistical Mechanics (cond-mat.stat-mech),Unread},
  file = {/home/filconscious/Library/On Bayesian Mechanics A Physics of and by Beliefs - Ramstead et al.pdf}
}

@article{Sales2019,
  title = {Locus Coeruleus Tracking of Prediction Errors Optimises Cognitive Flexibility: An Active Inference Model},
  author = {Sales, Anna C. and Friston, Karl J. and Jones, Matthew W. and Pickering, Anthony E. and Moran, Rosalyn J.},
  date = {2019},
  journaltitle = {PLOS Computational Biology},
  volume = {15},
  number = {1},
  pages = {1--24},
  publisher = {{Public Library of Science}},
  doi = {10.1371/journal.pcbi.1006267},
  url = {https://doi.org/10.1371/journal.pcbi.1006267},
  abstract = {Author summary The brain uses sensory information to build internal models and make predictions about the world. When errors of prediction occur, models must be updated to ensure desired outcomes are still achieved. Neuromodulator chemicals provide a possible pathway for triggering such changes in brain state. One such neuromodulator, noradrenaline, originates predominantly from a cluster of neurons in the brainstem—the locus coeruleus (LC)—and plays a key role in behaviour, for instance, in determining the balance between exploiting or exploring the environment. Here we use Active Inference (AI), a mathematical model of perception and action, to formally describe LC function. We propose that LC activity is triggered by errors in prediction and that the subsequent release of noradrenaline alters the rate of learning about the environment. Biologically, this describes an LC-cortex feedback loop promoting behavioural flexibility in times of uncertainty. We model LC output as a simulated animal performs two tasks known to elicit archetypal responses. We find that experimentally observed ‘phasic’ and ‘tonic’ patterns of LC activity emerge naturally, and that modulation of learning rates improves task performance. This provides a simple, unified computational account of noradrenergic computational function within a general model of behaviour.},
  langid = {english},
  keywords = {Read},
  file = {/home/filconscious/Library/Locus Coeruleus tracking of prediction errors - S1 Appendix - Sales et al.pdf;/home/filconscious/Library/Locus Coeruleus tracking of prediction errors - Sales et al.pdf}
}

@article{Schwartenbeck2019,
  title = {Computational Mechanisms of Curiosity and Goal-Directed Exploration},
  author = {Schwartenbeck, Philipp and Passecker, Johannes and Hauser, Tobias U. and Fitzgerald, Thomas H.B. and Kronbichler, Martin and Friston, Karl J.},
  date = {2019},
  journaltitle = {eLife},
  volume = {8},
  pages = {1--45},
  issn = {2050084X},
  doi = {10.7554/eLife.41703},
  abstract = {Successful behaviour depends on the right balance between maximising reward and soliciting information about the world. Here, we show how different types of information-gain emerge when casting behaviour as surprise minimisation. We present two distinct mechanisms for goal-directed exploration that express separable profiles of active sampling to reduce uncertainty. ‘Hidden state' exploration motivates agents to sample unambiguous observations to accurately infer the (hidden) state of the world. Conversely, ‘model parameter' exploration, compels agents to sample outcomes associated with high uncertainty, if they are informative for their representation of the task structure. We illustrate the emergence of these types of information-gain, termed active inference and active learning, and show how these forms of exploration induce distinct patterns of ‘Bayes-optimal' behaviour. Our findings provide a computational framework for understanding how distinct levels of uncertainty systematically affect the exploration-exploitation trade-off in decision- making.},
  keywords = {active inference,active learning,curiosity,exploitation,exploration,intrinsic motivation,neuroscience,none,Read,Relevant},
  file = {/home/filconscious/Library/Computational mechanisms of curiosity - Schwartenbeck et al.pdf}
}

@article{Smith2021,
  title = {A Step-by-Step Tutorial on Active Inference and Its Application to Empirical Data},
  author = {Smith, Ryan and Friston, Karl and Whyte, Christopher},
  date = {2021},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/b4jm6},
  url = {http://europepmc.org/abstract/PPR/PPR321279},
  abstract = {The active inference framework, and in particular its recent formulation as a partially observable Markov decision process (POMDP), has gained increasing popularity in recent years as a useful approach for modelling neurocognitive processes. This framework is highly general and flexible in its ability to be customized to model any cognitive process, as well as simulate predicted neuronal responses based on its accompanying neural process theory. It also affords both simulation experiments for proof of principle and behavioral modelling for empirical studies. However, there are limited resources that explain how to build and run these models in practice, which limits their widespread use. Most introductions assume a technical background in programming, mathematics, and machine learning. In this paper we offer a step-by-step tutorial on how to build POMDPs, run simulations using standard MATLAB routines, and fit these models to empirical data. We assume a minimal background in programming and mathematics, thoroughly explain all equations, and provide exemplar scripts that can be customized for both theoretical and empirical studies. Our goal is to provide the reader with the requisite background knowledge and practical tools to apply active inference to their own research. We also provide optional technical sections and several appendices, which offer the interested reader additional technical details. This tutorial should provide the reader with all the tools necessary to use these models and to follow emerging advances in active inference research.\&lt;/p\&gt;},
  keywords = {Relevant,Unread},
  file = {/home/filconscious/Library/A Step-by-Step Tutorial on Active Inference and its Application (preprint) - Smith et al.pdf}
}

@article{Smith2022,
  title = {A Step-by-Step Tutorial on Active Inference and Its Application to Empirical Data},
  author = {Smith, Ryan and Friston, Karl J. and Whyte, Christopher J.},
  date = {2022-04-01},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {107},
  pages = {102632},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2021.102632},
  url = {https://www.sciencedirect.com/science/article/pii/S0022249621000973},
  abstract = {The active inference framework, and in particular its recent formulation as a partially observable Markov decision process (POMDP), has gained increasing popularity in recent years as a useful approach for modeling neurocognitive processes. This framework is highly general and flexible in its ability to be customized to model any cognitive process, as well as simulate predicted neuronal responses based on its accompanying neural process theory. It also affords both simulation experiments for proof of principle and behavioral modeling for empirical studies. However, there are limited resources that explain how to build and run these models in practice, which limits their widespread use. Most introductions assume a technical background in programming, mathematics, and machine learning. In this paper we offer a step-by-step tutorial on how to build POMDPs, run simulations using standard MATLAB routines, and fit these models to empirical data. We assume a minimal background in programming and mathematics, thoroughly explain all equations, and provide exemplar scripts that can be customized for both theoretical and empirical studies. Our goal is to provide the reader with the requisite background knowledge and practical tools to apply active inference to their own research. We also provide optional technical sections and multiple appendices, which offer the interested reader additional technical details. This tutorial should provide the reader with all the tools necessary to use these models and to follow emerging advances in active inference research.},
  keywords = {Active inference,Bayesian inference,Computational neuroscience,Decision-making,Learning,Machine learning,Relevant,Unread},
  file = {/home/filconscious/Library/A step-by-step tutorial on active inference and its application to empirical data - Smith et al.pdf}
}

@article{Tschantz2020b,
  title = {Learning Action-Oriented Models through Active Inference},
  author = {Tschantz, Alexander and Seth, Anil K. and Buckley, Christopher L.},
  date = {2020-04-23},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {16},
  number = {4},
  pages = {e1007805},
  publisher = {{Public Library of Science}},
  doi = {10.1371/journal.pcbi.1007805},
  url = {https://doi.org/10.1371/journal.pcbi.1007805},
  abstract = {Author summary Within the popular framework of ‘active inference’, organisms learn internal models of their environments and use the models to guide goal-directed behaviour. A challenge for this framework is to explain how such models can be learned in practice, given (i) the rich complexity of natural environments, and (ii) the circular dependence of model learning and sensory sampling, which may lead to behaviourally suboptimal models being learned. Here, we develop an approach in which organisms selectively model those aspects of the environment that are relevant for acting in a goal-directed manner. Learning such ‘action-oriented’ models requires that agents balance information-seeking and goal-directed actions in a principled manner, such that both learning and information seeking are contextualised by goals. Using a combination of theory and simulation modelling, we show that this approach allows simple but effective models to be learned from relatively few interactions with the environment. Crucially, our results suggest that action-oriented models can support adaptive behaviour in spite of, and indeed because of, their departure from accurate representations of the environment.},
  keywords = {Read},
  file = {/home/filconscious/Library/Learning action-oriented models through active inference - Tschantz et al.pdf}
}

@article{Tschantz2022a,
  title = {Simulating Homeostatic, Allostatic and Goal-Directed Forms of Interoceptive Control Using Active Inference},
  author = {Tschantz, Alexander and Barca, Laura and Maisto, Domenico and Buckley, Christopher L. and Seth, Anil K. and Pezzulo, Giovanni},
  date = {2022},
  journaltitle = {Biological Psychology},
  shortjournal = {Biological Psychology},
  volume = {169},
  pages = {108266},
  issn = {0301-0511},
  doi = {10.1016/j.biopsycho.2022.108266},
  url = {https://www.sciencedirect.com/science/article/pii/S0301051122000084},
  abstract = {The adaptive regulation of bodily and interoceptive parameters, such as body temperature, thirst and hunger is a central problem for any biological organism. Here, we present a series of simulations using the framework of active inference to formally characterize interoceptive control and some of its dysfunctions. We start from the premise that the goal of interoceptive control is to minimize a discrepancy between expected and actual interoceptive sensations (i.e., a prediction error or free energy). Importantly, living organisms can achieve this goal by using various forms of interoceptive control: homeostatic, allostatic and goal-directed. We provide a computationally-guided analysis of these different forms of interoceptive control, by showing that they correspond to distinct generative models within Active inference. We discuss how these generative models can support empirical research through enabling fine-grained predictions about physiological and brain signals that may accompany both adaptive and maladaptive interoceptive control.},
  langid = {english},
  keywords = {Active inference,Allostasis,Homeostasis,Interoception,Predictive coding,Unread},
  file = {/home/filconscious/Library/Simulating homeostatic, allostatic and goal-directed forms of interoceptive control using active inference - Tschantz et al.pdf}
}

@article{VanDeLaar2019,
  title = {Simulating Active Inference Processes by Message Passing},
  author = {family=Laar, given=Thijs W., prefix=van de, useprefix=true and family=Vries, given=Bert, prefix=de, useprefix=true},
  date = {2019},
  journaltitle = {Frontiers Robotics AI},
  volume = {6},
  pages = {1--15},
  issn = {22969144},
  doi = {10.3389/frobt.2019.00020},
  abstract = {The free energy principle (FEP) offers a variational calculus-based description for how biological agents persevere through interactions with their environment. Active inference (AI) is a corollary of the FEP, which states that biological agents act to fulfill prior beliefs about preferred future observations (target priors). Purposeful behavior then results from variational free energy minimization with respect to a generative model of the environment with included target priors. However, manual derivations for free energy minimizing algorithms on custom dynamic models can become tedious and error-prone. While probabilistic programming (PP) techniques enable automatic derivation of inference algorithms on free-form models, full automation of AI requires specialized tools for inference on dynamic models, together with the description of an experimental protocol that governs the interaction between the agent and its simulated environment. The contributions of the present paper are two-fold. Firstly, we illustrate how AI can be automated with the use of ForneyLab, a recent PP toolbox that specializes in variational inference on flexibly definable dynamic models. More specifically, we describe AI agents in a dynamic environment as probabilistic state space models (SSM) and perform inference for perception and control in these agents by message passing on a factor graph representation of the SSM. Secondly, we propose a formal experimental protocol for simulated AI. We exemplify how this protocol leads to goal-directed behavior for flexibly definable AI agents in two classical RL examples, namely the Bayesian thermostat and the mountain car parking problems.},
  issue = {MAR},
  keywords = {active inference,Forney-style factor graphs,free energy principle,message passing,Relevant,state-space models,Unread},
  file = {/home/filconscious/Library/Simulating Active Inference Processes - van de Laar et al.pdf}
}

@article{Walsh2020,
  title = {Evaluating the Neurophysiological Evidence for Predictive Processing as a Model of Perception},
  author = {Walsh, Kevin S. and McGovern, David P. and Clark, Andy and O'Connell, Redmond G.},
  date = {2020},
  journaltitle = {Annals of the New York Academy of Sciences},
  volume = {1464},
  number = {1},
  eprint = {32147856},
  eprinttype = {pmid},
  pages = {242--268},
  issn = {17496632},
  doi = {10.1111/nyas.14321},
  abstract = {For many years, the dominant theoretical framework guiding research into the neural origins of perceptual experience has been provided by hierarchical feedforward models, in which sensory inputs are passed through a series of increasingly complex feature detectors. However, the long-standing orthodoxy of these accounts has recently been challenged by a radically different set of theories that contend that perception arises from a purely inferential process supported by two distinct classes of neurons: those that transmit predictions about sensory states and those that signal sensory information that deviates from those predictions. Although these predictive processing (PP) models have become increasingly influential in cognitive neuroscience, they are also criticized for lacking the empirical support to justify their status. This limited evidence base partly reflects the considerable methodological challenges that are presented when trying to test the unique predictions of these models. However, a confluence of technological and theoretical advances has prompted a recent surge in human and nonhuman neurophysiological research seeking to fill this empirical gap. Here, we will review this new research and evaluate the degree to which its findings support the key claims of PP.},
  keywords = {neurophysiology,perception,perceptual inference,predictive coding,predictive processing,Relevant,Unread},
  file = {/home/filconscious/Library/Evaluating the neurophysiological evidence for predictive - Walsh et al.pdf}
}

@article{Wauthier2022,
  title = {Model {{Reduction Through Progressive Latent Space Pruning}} in {{Deep Active Inference}}},
  author = {Wauthier, Samuel T. and De Boom, Cedric and Çatal, Ozan and Verbelen, Tim and Dhoedt, Bart},
  date = {2022},
  journaltitle = {Frontiers in Neurorobotics},
  shortjournal = {Frontiers in Neurorobotics},
  volume = {16},
  pages = {1--16},
  issn = {1662-5218},
  url = {https://www.frontiersin.org/article/10.3389/fnbot.2022.795846},
  abstract = {Although still not fully understood, sleep is known to play an important role in learning and in pruning synaptic connections. From the active inference perspective, this can be cast as learning parameters of a generative model and Bayesian model reduction, respectively. In this article, we show how to reduce dimensionality of the latent space of such a generative model, and hence model complexity, in deep active inference during training through a similar process. While deep active inference uses deep neural networks for state space construction, an issue remains in that the dimensionality of the latent space must be specified beforehand. We investigate two methods that are able to prune the latent space of deep active inference models. The first approach functions similar to sleep and performs model reduction post hoc. The second approach is a novel method which is more similar to reflection, operates during training and displays “aha” moments when the model is able to reduce latent space dimensionality. We show for two well-known simulated environments that model performance is retained in the first approach and only diminishes slightly in the second approach. We also show that reconstructions from a real world example are indistinguishable before and after reduction. We conclude that the most important difference constitutes a trade-off between training time and model performance in terms of accuracy and the ability to generalize, via minimization of model complexity.},
  langid = {english},
  keywords = {Unread},
  file = {/home/filconscious/Library/Model Reduction Through Progressive Latent Space Pruning in Deep Active Inference - Wauthier et al.pdf}
}
